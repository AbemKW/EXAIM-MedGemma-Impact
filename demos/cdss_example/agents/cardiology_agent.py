from typing import AsyncIterator
from langchain_core.prompts import ChatPromptTemplate
from .demo_base_agent import DemoBaseAgent
from exaid_core.llm import mas_llm
from demos.cdss_example.callbacks.agent_streaming_callback import AgentStreamingCallback


class CardiologyAgent(DemoBaseAgent):
    """Cardiology specialist agent for cardiovascular assessment and recommendations"""
    
    def __init__(self, agent_id: str = "CardiologyAgent"):
        super().__init__(agent_id)
        self.llm = mas_llm
        self.system_prompt = (
            "You are the Cardiology specialist in a multi-agent clinical decision support system.\n\n"
            "MULTI-AGENT SYSTEM CONTEXT:\n"
            "- This is a collaborative MAS with Laboratory, Cardiology, Internal Medicine, and Radiology specialists\n"
            "- An Orchestrator coordinates the workflow and maintains a running summary\n"
            "- You will receive: the original case, a running summary (compressed context from prior work), "
            "a recent update (raw output from the most recent specialist), and your specific task\n"
            "- Build on the running summary and recent updates - do NOT restart analysis from scratch\n"
            "- Provide ONLY your domain reasoning - no summaries, critiques, workflow management, or agent coordination\n\n"
            "YOUR EXPERTISE:\n"
            "You are an expert cardiologist specializing in cardiovascular medicine. Your expertise includes:\n"
            "- Acute coronary syndromes (STEMI, NSTEMI, unstable angina)\n"
            "- Heart failure (systolic and diastolic dysfunction)\n"
            "- Arrhythmias and conduction disorders\n"
            "- Valvular heart disease\n"
            "- Cardiomyopathies\n"
            "- Hypertension and cardiovascular risk stratification\n"
            "- ECG interpretation and cardiac biomarker analysis\n\n"
            "APPROACH:\n"
            "Use Chain of Thought reasoning. Show your analytical process:\n"
            "1. Review cardiovascular findings in context of the case and prior assessments\n"
            "2. Analyze cardiac symptoms, risk factors, and biomarkers\n"
            "3. Interpret ECG findings and imaging results if available\n"
            "4. Assess urgency and need for immediate intervention\n"
            "5. Consider differential diagnoses for cardiovascular presentations\n"
            "6. Recommend appropriate cardiac workup and treatment\n\n"
            "Focus on cardiovascular assessment - the Orchestrator handles coordination and synthesis."
        )
    
    async def act_stream(self, input: str) -> AsyncIterator[str]:
        """Stream tokens as they are generated by the LLM
        
        Ephemeral prompt building for single turn - no conversation history.
        
        Args:
            input: Context string containing case, running_summary, recent_delta, and task
            
        Yields:
            Tokens as strings as they are generated
        """
        # Build prompt for this turn only (no history)
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("user", input)
        ])
        
        chain = prompt | self.llm
        callback = AgentStreamingCallback(agent_id=self.agent_id)
        
        try:
            async for chunk in chain.astream({}, callbacks=[callback]):
                if hasattr(chunk, 'content'):
                    content = chunk.content
                    if content:
                        yield content
                elif isinstance(chunk, str) and chunk:
                    yield chunk
                elif isinstance(chunk, dict) and 'content' in chunk:
                    if chunk['content']:
                        yield chunk['content']
        except ValueError as e:
            if "No generation chunks were returned" in str(e):
                print(f"[WARNING] Streaming failed for {self.agent_id}, falling back to non-streaming mode")
                # Fallback: use ainvoke
                response = await chain.ainvoke({})
                for char in response.content:
                    yield char
            else:
                raise
