"""LangChain callback handler for token-level streaming to WebSocket message queue."""
import asyncio
from datetime import datetime
from langchain_core.callbacks import AsyncCallbackHandler
from demos.cdss_example.message_bus import message_queue


class AgentStreamingCallback(AsyncCallbackHandler):
    """Callback handler that forwards streamed tokens to the WebSocket message queue.
    
    Each token is queued with the agent_id for proper routing to WebSocket clients.
    """
    
    def __init__(self, agent_id: str):
        """Initialize the callback handler with an agent ID.
        
        Args:
            agent_id: The identifier for the agent generating the tokens
        """
        super().__init__()
        self.agent_id = agent_id
    
    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        """Called when a new token is generated by the LLM.
        
        Args:
            token: The newly generated token string
            **kwargs: Additional keyword arguments (ignored)
        """
        message = {
            "type": "token",
            "agent_id": self.agent_id,
            "token": token,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            message_queue.put_nowait(message)
        except asyncio.QueueFull:
            print(f"Warning: Message queue full for agent {self.agent_id}, token dropped.")
        except Exception as e:
            print(f"Error queueing message for agent {self.agent_id}: {e}")

