# EXAID Evaluation - Multi-Agent System Generation Configuration
# This file defines parameters for MAS trace generation using MAC

# =============================================================================
# MAS Generation Mode
# =============================================================================
mode: "mac_integration"

# =============================================================================
# MAC Integration Configuration
# =============================================================================
mac:
  enabled: true
  
  # Path to MAC module (inside Docker container)
  module_path: "/app/third_party/mac"
  
  # Pinned commit hash of the MAC submodule used for trace generation.
  # This duplicates the git submodule pin for explicit provenance
  # in evaluation artifacts and metadata logs.
  # Repository: https://github.com/AbemKW/mac-streaming-traces
  # Fork of original MAC repo with token-level streaming instrumentation
  commit: "1d5b227afa64fe3dd5eb7b7c0ef778a09501b220"
  
  # Base model used by MAC for agent conversations
  base_model: "gpt-4o-mini"
  
  # Decoding parameters
  # IMPORTANT: Decoding parameters (temperature, sampling) are controlled by MAC
  # internally per agent role. EXAID does not override these parameters.
  decoding:
    max_tokens: 4096  # Logged for documentation only
    note: "Decoding parameters (temperature, sampling) are controlled by MAC internally and are not overridden by EXAID"

# =============================================================================
# Text Unit Accounting (Vendor-Agnostic)
# =============================================================================
# All evaluation metrics use Character-Normalized Token Units (CTU)
# This ensures deterministic, offline-computable, reproducible metrics

text_unit:
  name: "CTU"
  definition: "ceil(len(text) / 4)"
  # The ~4 characters per unit heuristic reflects average token densities observed
  # across modern LLM tokenizers (OpenAI, LLaMA, Gemini, Claude). CTU is model-agnostic
  # and is NOT a tokenizerâ€”it is a deterministic, vendor-independent normalization unit.
  reference: "Average subword tokenizer density (~4 chars/token) across contemporary LLMs"
  applies_to: "both input traces and output summaries"

# =============================================================================
# Output Configuration
# =============================================================================
output:
  # Output directory (relative to evals/)
  traces_dir: "data/traces"
  # Output file format
  format: "jsonl.gz"
  # Compression level (1-9)
  compression_level: 6

# =============================================================================
# Documentation Tracking
# =============================================================================
# Used to track when documentation was last updated for this integration

documentation:
  # EXAID commit hash when this configuration was last updated
  last_updated_commit: "pending"
  # Date of last documentation update
  last_updated_date: "2024-12-24"
